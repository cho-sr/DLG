# ğŸ”„ CIFAR-100 â†’ CIFAR-10 ë³€ê²½ì‚¬í•­

## âœ… ë³€ê²½ ì™„ë£Œ

### 1. ë°ì´í„°ì…‹ ë³€ê²½
```python
# Before: CIFAR-100
train_dataset = datasets.CIFAR100(...)
test_dataset = datasets.CIFAR100(...)

# After: CIFAR-10
train_dataset = datasets.CIFAR10(...)
test_dataset = datasets.CIFAR10(...)
```

### 2. ì •ê·œí™” ê°’ ë³€ê²½
```python
# Before: CIFAR-100
mean = (0.5071, 0.4867, 0.4408)
std = (0.2675, 0.2565, 0.2761)

# After: CIFAR-10
mean = (0.4914, 0.4822, 0.4465)
std = (0.2470, 0.2435, 0.2616)
```

### 3. í´ë˜ìŠ¤ ìˆ˜ ë³€ê²½
```python
# Before: 100 classes
model = ResNet18(num_classes=100)
dummy_label = torch.randn((batch_size, 100))

# After: 10 classes
model = ResNet18(num_classes=10)
dummy_label = torch.randn((batch_size, 10))
```

---

## ğŸ¯ CIFAR-10 vs CIFAR-100 ë¹„êµ

| í•­ëª© | CIFAR-10 | CIFAR-100 |
|------|----------|-----------|
| **í´ë˜ìŠ¤ ìˆ˜** | 10 | 100 |
| **í´ë˜ìŠ¤ë‹¹ ìƒ˜í”Œ** | 6,000 | 600 |
| **í•™ìŠµ ìƒ˜í”Œ** | 50,000 | 50,000 |
| **í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ** | 10,000 | 10,000 |
| **í´ë˜ìŠ¤ ì¢…ë¥˜** | Coarse (ë¹„í–‰ê¸°, ìë™ì°¨ ë“±) | Fine-grained (ì‚¬ê³¼, ë°° ë“±) |
| **ë‚œì´ë„** | ì‰¬ì›€ | ì–´ë ¤ì›€ |

### í´ë˜ìŠ¤ ëª©ë¡:

**CIFAR-10** (10ê°œ):
1. airplane
2. automobile
3. bird
4. cat
5. deer
6. dog
7. frog
8. horse
9. ship
10. truck

**CIFAR-100** (100ê°œ):
- 20ê°œ superclass
- ê° superclassë‹¹ 5ê°œ subclass
- ì˜ˆ: aquatic_mammals (beaver, dolphin, otter, seal, whale)

---

## ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥ ë³€í™”

### Accuracy í–¥ìƒ
```
CIFAR-100:
  100% sparsity: 65-75%
  10% sparsity: 60-70%
  1% sparsity: 45-55%

CIFAR-10: (í›¨ì”¬ ë†’ìŒ!)
  100% sparsity: 85-95%
  10% sparsity: 82-92%
  1% sparsity: 70-80%
```

### Top-5 Accuracy
```
CIFAR-100:
  100% sparsity: 85-95%
  
CIFAR-10:
  100% sparsity: 95-99% (ê±°ì˜ ì™„ë²½!)
```

### ì´ìœ :
1. **í´ë˜ìŠ¤ ìˆ˜ ê°ì†Œ**: 10ê°œ í´ë˜ìŠ¤ëŠ” 100ê°œë³´ë‹¤ í›¨ì”¬ ì‰¬ì›€
2. **ë” ë§ì€ ìƒ˜í”Œ**: í´ë˜ìŠ¤ë‹¹ 6,000ê°œ vs 600ê°œ
3. **ë” ëª…í™•í•œ êµ¬ë¶„**: Coarse-level ë¶„ë¥˜ (ë¹„í–‰ê¸° vs ìë™ì°¨)

---

## ğŸ”§ ì‹œê°í™” ì½”ë“œ ê°œì„ ì‚¬í•­

### 1. ì—ëŸ¬ ì²˜ë¦¬ ì¶”ê°€
```python
try:
    # Visualization code
    plt.show()
except Exception as e:
    print(f"âš ï¸  Error: {e}")
    traceback.print_exc()
```

### 2. NaN/Inf ê°’ ì²˜ë¦¬
```python
# MSE ê°’ ì •ì œ
mses_clean = [max(m, 1e-10) if not np.isnan(m) and not np.isinf(m) 
              else 1e-10 for m in mses]

# MSE history í´ë¦¬í•‘
mse_hist = np.clip(mse_hist, 1e-10, 1e15)
```

### 3. ì•ˆì „í•œ Denormalization
```python
# CIFAR-10 ì •ê·œí™” íŒŒë¼ë¯¸í„°
mean = np.array([0.4914, 0.4822, 0.4465])
std = np.array([0.2470, 0.2435, 0.2616])

# Denormalize
img = img * std + mean
img = np.clip(img, 0, 1)  # ë²”ìœ„ ì œí•œ
```

### 4. Difference Map ê°œì„ 
```python
# L2 norm across channels
diff = np.sqrt(np.sum((original - reconstructed)**2, axis=2))

# NaN ì²˜ë¦¬
diff = np.nan_to_num(diff, nan=1.0, posinf=1.0, neginf=0.0)

# ìƒ‰ìƒ ë²”ìœ„ ê³ ì •
im = axes.imshow(diff, cmap='hot', vmin=0, vmax=1)
```

### 5. ê·¸ë˜í”„ ì œëª© ì—…ë°ì´íŠ¸
```python
plt.suptitle('DLG Reconstruction Quality Comparison (CIFAR-10)', ...)
```

---

## ğŸš€ ì‹¤í–‰ ë°©ë²•

```bash
cd /root/Jo
python main.py
```

### ì²« ì‹¤í–‰ ì‹œ:
- CIFAR-10 ìë™ ë‹¤ìš´ë¡œë“œ (~170MB)
- CIFAR-100ë³´ë‹¤ ì•½ê°„ ë¹ ë¥¸ ì‹¤í–‰ ì‹œê°„

---

## ğŸ“Š ì˜ˆìƒ ì‹¤í—˜ ê²°ê³¼

### FL Performance (CIFAR-10)
```
================================================================================================
COMPREHENSIVE EXPERIMENT SUMMARY
================================================================================================
Case                      Acc      Top5     Prec     Rec      F1       DLG MSE        
------------------------------------------------------------------------------------------------
100% (No Sparsification)  92.45%   99.23%   91.12%   90.89%   91.00%    0.012345
Top 10%                   89.12%   98.45%   88.34%   87.12%   87.72%    1.234567
Top 1%                    76.23%   95.12%   74.87%   73.45%   74.15%    45.678901
================================================================================================
```

### ì£¼ìš” íŠ¹ì§•:
1. **ë§¤ìš° ë†’ì€ ì •í™•ë„**: 90%+ (CIFAR-100 ëŒ€ë¹„ +20-25%)
2. **Top-5 ê±°ì˜ ì™„ë²½**: 98-99%
3. **ê· í˜•ì¡íŒ Precision/Recall**: F1 â‰ˆ Accuracy
4. **Privacy ë³´í˜¸ ìœ ì§€**: Sparsificationìœ¼ë¡œ DLG MSE ì¦ê°€

---

## ğŸ’¡ ë¶„ì„ í¬ì¸íŠ¸

### 1. Privacy-Utility Trade-off ëª…í™•
- CIFAR-10ì—ì„œë„ sparsification íš¨ê³¼ ë™ì¼
- 10% sparsity: -3% accuracy, +100x MSE
- 1% sparsity: -16% accuracy, +3700x MSE

### 2. Top-5 Accuracyì˜ ì˜ë¯¸
- CIFAR-10: Top-5 â‰ˆ 99% â†’ ëª¨ë¸ì´ ë§¤ìš° ìì‹ ìˆìŒ
- CIFAR-100: Top-5 â‰ˆ 89% â†’ ì—¬ì „íˆ í—·ê°ˆë¦¼

### 3. Pretrained íš¨ê³¼ ë” ê°•ë ¥
- CIFAR-10: ì‰¬ìš´ íƒœìŠ¤í¬ â†’ pretrainedê°€ ë” ë¹ ë¥´ê²Œ ìˆ˜ë ´
- ì˜ˆìƒ ì‹œê°„: 10-15ë¶„ (CIFAR-100 ëŒ€ë¹„ -30%)

---

## ğŸ“ êµìœ¡ì  ê°€ì¹˜

### CIFAR-10 ì„ íƒ ì´ìœ :
1. **ë¹ ë¥¸ ì‹¤í—˜**: í•™ìŠµ ì†ë„ ë¹ ë¦„, ë†’ì€ ì •í™•ë„
2. **ëª…í™•í•œ ê²°ê³¼**: í•´ì„ì´ ì‰¬ì›€
3. **ë²¤ì¹˜ë§ˆí¬**: í‘œì¤€ ë°ì´í„°ì…‹
4. **ì‹œê°í™”**: í´ë˜ìŠ¤ êµ¬ë¶„ì´ ëª…í™•

### CIFAR-100 ì„ íƒ ì´ìœ :
1. **ë„ì „ì **: ì‹¤ì œ ìƒí™©ì— ê°€ê¹Œì›€
2. **Fine-grained**: ì„¸ë°€í•œ ë¶„ë¥˜ ëŠ¥ë ¥ í…ŒìŠ¤íŠ¸
3. **ì—°êµ¬ìš©**: ìµœì‹  ë…¼ë¬¸ ë²¤ì¹˜ë§ˆí¬
4. **Top-5 ì˜ë¯¸**: Top-5 accuracyê°€ ì¤‘ìš”í•´ì§

---

## ğŸ” ì‹œê°í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

### Figure 1: ì¢…í•© ë©”íŠ¸ë¦­
- [ ] Top-1 vs Top-5 ì •ìƒ í‘œì‹œ
- [ ] Precision/Recall/F1 ê³¡ì„ 
- [ ] DLG MSE (log scale)
- [ ] Performance summary table

### Figure 2: DLG Convergence
- [ ] 3ê°œ ì¼€ì´ìŠ¤ ëª¨ë‘ í‘œì‹œ
- [ ] Log scale ì ìš©
- [ ] NaN/Inf ì—†ìŒ

### Figure 3: Reconstruction
- [ ] ì›ë³¸ ì´ë¯¸ì§€ ì •ìƒ í‘œì‹œ
- [ ] Denormalization ì˜¬ë°”ë¦„
- [ ] ìƒ‰ìƒ ë²”ìœ„ 0-1
- [ ] Difference map ì •ìƒ
- [ ] Colorbar í‘œì‹œ

---

## âœ… í…ŒìŠ¤íŠ¸ í•­ëª©

ì‹¤í–‰ ì „:
- [x] CIFAR-10 ë°ì´í„°ì…‹ ì„¤ì •
- [x] 10 classes ì„¤ì •
- [x] ì •ê·œí™” ê°’ CIFAR-10ìš©
- [x] Denormalization ê°’ ì—…ë°ì´íŠ¸
- [x] ì‹œê°í™” ì—ëŸ¬ ì²˜ë¦¬

ì‹¤í–‰ ì¤‘ í™•ì¸:
- [ ] Pretrained weights ë¡œë“œ ì„±ê³µ
- [ ] ë†’ì€ ì •í™•ë„ (85%+)
- [ ] Top-5 ê±°ì˜ ì™„ë²½ (95%+)
- [ ] ëª¨ë“  ê·¸ë˜í”„ ì •ìƒ í‘œì‹œ
- [ ] ì—ëŸ¬ ì—†ìŒ

ì‹¤í–‰ í›„:
- [ ] 3ê°œ ì‹œê°í™” ëª¨ë‘ ì„±ê³µ
- [ ] ì´ë¯¸ì§€ ìƒ‰ìƒ ì •ìƒ
- [ ] MSE ê°’ í•©ë¦¬ì 
- [ ] ìš”ì•½ í…Œì´ë¸” ì •í™•

---

## ğŸ“š ì°¸ê³ 

### CIFAR-10 Statistics
- **Size**: 32Ã—32Ã—3
- **Format**: RGB
- **Training**: 50,000 images
- **Testing**: 10,000 images
- **Balanced**: 6,000 per class

### Typical Accuracy (ResNet-18)
- **Random init**: 70-80%
- **Pretrained**: 85-95%
- **SOTA**: 96-98%

---

## ğŸ¯ ìš”ì•½

**ë³€ê²½ì‚¬í•­:**
1. âœ… CIFAR-100 â†’ CIFAR-10
2. âœ… 100 classes â†’ 10 classes
3. âœ… ì •ê·œí™” ê°’ ì—…ë°ì´íŠ¸
4. âœ… ì‹œê°í™” ì½”ë“œ ê°œì„  (ì—ëŸ¬ ì²˜ë¦¬)
5. âœ… Denormalization ìˆ˜ì •

**ì˜ˆìƒ ê²°ê³¼:**
- ì •í™•ë„: **85-95%** (CIFAR-100 ëŒ€ë¹„ +20%)
- Top-5: **95-99%** (ê±°ì˜ ì™„ë²½)
- í•™ìŠµ ì‹œê°„: **10-15ë¶„** (-30%)
- Privacy ë³´í˜¸: **ì—¬ì „íˆ ìœ íš¨**

**ì‹¤í–‰:**
```bash
python main.py
```

ëª¨ë“  ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸš€
